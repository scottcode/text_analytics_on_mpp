{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification problem on the Twenty News Groups dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we'll use a simple <i>[bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model)</i> model of term frequencies to create feature vectors of the emails in the <i>twenty newsgroups</i> dataset and build a classifier to identify emails belonging to <i>computer related topics</i> and those which aren't.\n",
    "\n",
    "More information on the <i>Twenty Newsgroups</i> dataset can be found on the [UCI website](http://kdd.ics.uci.edu/databases/20newsgroups/20newsgroups.html)\n",
    "\n",
    "**Prerequisites:** \n",
    "* Load and preprocess the 20 newsgroups data set using the scripts in the 00_prepare_data_set folder of the repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup database connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll reuse our module from the previous notebook (***`00_database_connectivity_setup.ipynb`***) to establish connectivity to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shajek/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%run '00_database_connectivity_setup.ipynb'\n",
    "%matplotlib inline\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your connection object is ***`conn`***:\n",
    "1. Queries: You can run your queries using ***```psql.read_sql(\"\"\"<YOUR SQL>\"\"\", conn)```***.\n",
    "2. Create/Delete/Updates: You can run these statements using ***```psql.execute(\"\"\"<YOUR SQL>\"\"\", conn)```***, followed by a ***```conn.commit()```*** command to ensure your transaction is committed. Otherwise your changes will be rolledback if you terminate your kernel.\n",
    "\n",
    "If you created a new connection object (say to connect to a new cluster) as shown in the last section of `00_database_connectivity_setup.ipynb` notebook, use that connection object where needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create a bag of words model with term-frequencies as the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#UDF to compute term-frequency vector\n",
    "sql = \"\"\"\n",
    "    drop function if exists YOUR_SCHEMA.tf_vectorize(float8[], text[], text[]);\n",
    "    create or replace function YOUR_SCHEMA.tf_vectorize(\n",
    "        tf_arr float8[],\n",
    "        tokens_arr text[],\n",
    "        vocabulary_arr text[]\n",
    "    )\n",
    "    returns float8[]\n",
    "    as\n",
    "    $$\n",
    "        result = [0 for _ in xrange(len(vocabulary_arr))]\n",
    "        idx_map = dict(map(lambda pr: reversed(pr), enumerate(vocabulary_arr)))\n",
    "        tf_dict = dict(zip(tokens_arr, tf_arr))\n",
    "        for key in tf_dict.keys():\n",
    "            if idx_map.has_key(key):\n",
    "                result[idx_map[key]] = tf_dict[key]\n",
    "        return result\n",
    "    $$language plpythonu;\n",
    "\"\"\"\n",
    "psql.execute(sql, conn)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "    drop table if exists YOUR_SCHEMA.twenty_news_groups_bow cascade;\n",
    "    create table YOUR_SCHEMA.twenty_news_groups_bow\n",
    "    as\n",
    "    (\n",
    "        select\n",
    "            doc_id,\n",
    "            YOUR_SCHEMA.tf_vectorize(\n",
    "                tf_arr,\n",
    "                token_arr,\n",
    "                vocab_arr\n",
    "            ) as feature_vector\n",
    "        from\n",
    "            (\n",
    "                select\n",
    "                    doc_id,\n",
    "                    array_agg(tf order by token) as tf_arr,\n",
    "                    array_agg(token order by token) as token_arr\n",
    "                from\n",
    "                    YOUR_SCHEMA.twenty_news_groups_term_frequencies\n",
    "                group by doc_id\n",
    "            )t1,\n",
    "            (\n",
    "                select\n",
    "                    array_agg(token order by token) as vocab_arr\n",
    "                from \n",
    "                    YOUR_SCHEMA.twenty_news_groups_vocabulary\n",
    "            )t2\n",
    "    ) distributed randomly;\n",
    "\"\"\"\n",
    "psql.execute(sql, conn)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create train & test split    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "    -- Set the seed to ensure the random splits are repeatable\n",
    "    -- This is important if you want to measure performance \n",
    "    -- of classifiers based by varying the \"num_bits\" parameter\n",
    "    -- Note: You should run the setseed() statement and the following create temp table statement as a single\n",
    "    -- transaction.\n",
    "    select setseed(0.5);\n",
    "    drop table if exists bow_vector_train_test_split cascade;\n",
    "    create temp table bow_vector_train_test_split\n",
    "    as\n",
    "    (\n",
    "        select\n",
    "            t1.doc_id,\n",
    "            t1.feature_vector,\n",
    "            -- to create a binary classification problem\n",
    "            -- consider the task as being able to predict if a document is related to computers or not            \n",
    "            case \n",
    "                when t2.label ~* 'comp.*' then 1 \n",
    "                else 0\n",
    "            end as label,\n",
    "            random() as splitter\n",
    "        from\n",
    "            YOUR_SCHEMA.twenty_news_groups_bow t1,\n",
    "            YOUR_SCHEMA.twenty_news_groups t2\n",
    "        where\n",
    "            t1.doc_id = t2.doc_id\n",
    "        order by\n",
    "            doc_id\n",
    "    ) distributed randomly;\n",
    "\n",
    "    -- Training set\n",
    "    drop table if exists YOUR_SCHEMA.bow_vector_training_set cascade;\n",
    "    create table YOUR_SCHEMA.bow_vector_training_set\n",
    "    as\n",
    "    (\n",
    "        select \n",
    "            doc_id,\n",
    "            feature_vector,\n",
    "            label\n",
    "        from\n",
    "            bow_vector_train_test_split\n",
    "        where \n",
    "            splitter <= 0.75\n",
    "    ) distributed randomly;\n",
    "\n",
    "    -- Test set\n",
    "    drop table if exists YOUR_SCHEMA.bow_vector_test_set cascade;\n",
    "    create table YOUR_SCHEMA.bow_vector_test_set\n",
    "    as\n",
    "    (\n",
    "        select \n",
    "            doc_id,\n",
    "            feature_vector,\n",
    "            label\n",
    "        from\n",
    "            bow_vector_train_test_split\n",
    "        where \n",
    "            splitter > 0.75\n",
    "    ) distributed randomly; \n",
    "\"\"\"\n",
    "psql.execute(sql, conn)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3b3f49ffa062>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     );\n\u001b[1;32m     14\u001b[0m \"\"\"\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mpsql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shajek/anaconda/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(sql, con, cur, params)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mpandas_sql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandasSQL_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_cursor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpandas_sql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shajek/anaconda/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1399\u001b[0m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1402\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(_cls, name, type_code, display_size, internal_size, precision, scale, null_ok)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "    drop table if exists YOUR_SCHEMA.bow_vector_logregr_mdl;\n",
    "    drop table if exists YOUR_SCHEMA.bow_vector_logregr_mdl_summary;\n",
    "    select \n",
    "        madlib_1_10.logregr_train( \n",
    "            'YOUR_SCHEMA.bow_vector_training_set',\n",
    "            'YOUR_SCHEMA.bow_vector_logregr_mdl',\n",
    "            'label',\n",
    "            'feature_vector',\n",
    "            NULL,\n",
    "            20,\n",
    "            'irls'\n",
    "    );\n",
    "\"\"\"\n",
    "psql.execute(sql, conn)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>log_likelihood</th>\n",
       "      <th>std_err</th>\n",
       "      <th>z_stats</th>\n",
       "      <th>p_values</th>\n",
       "      <th>odds_ratios</th>\n",
       "      <th>condition_no</th>\n",
       "      <th>num_rows_processed</th>\n",
       "      <th>num_missing_rows_skipped</th>\n",
       "      <th>num_iterations</th>\n",
       "      <th>variance_covariance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>13</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   coef log_likelihood std_err z_stats p_values odds_ratios condition_no  \\\n",
       "0  None           None    None    None     None        None         None   \n",
       "\n",
       "  num_rows_processed num_missing_rows_skipped  num_iterations  \\\n",
       "0               None                     None              13   \n",
       "\n",
       "  variance_covariance  \n",
       "0                None  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psql.read_sql(\n",
    "    \"\"\"select * from YOUR_SCHEMA.bow_vector_logregr_mdl limit 10\"\"\",\n",
    "    conn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Score using the trained classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "    drop table if exists YOUR_SCHEMA.bow_vector_prediction_results cascade;\n",
    "    create table YOUR_SCHEMA.bow_vector_prediction_results\n",
    "    as\n",
    "    (\n",
    "        select\n",
    "            doc_id,\n",
    "            label as actual_label,\n",
    "            madlib.logregr_predict(\n",
    "                coef,\n",
    "                feature_vector\n",
    "            ) as predicted_label,            \n",
    "            madlib.logregr_predict_prob(\n",
    "                coef,\n",
    "                feature_vector\n",
    "            ) as predicted_label_proba\n",
    "        from\n",
    "            YOUR_SCHEMA.bow_vector_logregr_mdl mdl,\n",
    "            YOUR_SCHEMA.bow_vector_test_set test_set\n",
    "    ) distributed randomly;\n",
    "\"\"\"\n",
    "psql.execute(sql, conn)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_label_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id  actual_label predicted_label predicted_label_proba\n",
       "0       3             0            None                  None\n",
       "1      18             0            None                  None\n",
       "2      26             0            None                  None\n",
       "3      40             0            None                  None\n",
       "4      51             0            None                  None"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "    select\n",
    "        doc_id,\n",
    "        actual_label,\n",
    "        predicted_label,\n",
    "        predicted_label_proba\n",
    "    from\n",
    "        YOUR_SCHEMA.bow_vector_prediction_results\n",
    "\"\"\"\n",
    "df = psql.read_sql(sql, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-242aebfe2f9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                             \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'actual_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                             \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted_label_proba'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                             \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                         )\n\u001b[1;32m     11\u001b[0m \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shajek/anaconda/lib/python2.7/site-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \"\"\"\n\u001b[1;32m    504\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 505\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shajek/anaconda/lib/python2.7/site-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;31m# the indices associated with the distinct values. We also\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;31m# concatenate a value for the end of the curve.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m     \u001b[0mdistinct_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m     \u001b[0mthreshold_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdistinct_value_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shajek/anaconda/lib/python2.7/site-packages/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36mdiff\u001b[0;34m(a, n, axis)\u001b[0m\n\u001b[1;32m   1576\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslice1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslice2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1577\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1578\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslice1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslice2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'NoneType' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "fpr, tpr, thresholds = metrics.roc_curve(\n",
    "                            df['actual_label'].tolist(),\n",
    "                            df['predicted_label_proba'].tolist(), \n",
    "                            pos_label=1\n",
    "                        )\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "rocdf = pd.DataFrame(np.transpose([fpr, tpr, thresholds]), columns = ['fpr','tpr','thresholds'])\n",
    "rocdf.plot(x='fpr',y='tpr', label='AUC:{0}'.format(auc))\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Logistic regression model on bag-of-words vector of size {0}'.format(vocabulary_size))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
