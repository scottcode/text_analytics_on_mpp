{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess Twenty Newsgroups data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the exercises use email data from the <i>twenty newsgroups</i> data set. More information on the <i>Twenty Newsgroups</i> dataset can be found on the [UCI website](http://kdd.ics.uci.edu/databases/20newsgroups/20newsgroups.html). This notebook loads that data set and does preprocessing that is a prerequisite for most of the examples in this repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup database connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll reuse our module from the previous notebook (***`00_database_connectivity_setup.ipynb`***) to establish connectivity to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shajek/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%run '00_database_connectivity_setup.ipynb'\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your connection object is ***`conn`***:\n",
    "1. Queries: You can run your queries using ***```psql.read_sql(\"\"\"<YOUR SQL>\"\"\", conn)```***.\n",
    "2. Create/Delete/Updates: You can run these statements using ***```psql.execute(\"\"\"<YOUR SQL>\"\"\", conn)```***, followed by a ***```conn.commit()```*** command to ensure your transaction is committed. Otherwise your changes will be rolledback if you terminate your kernel.\n",
    "\n",
    "If you created a new connection object (say to connect to a new cluster) as shown in the last section of `00_database_connectivity_setup.ipynb` notebook, use that connection object where needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create your schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\n    create schema YOUR_SCHEMA;\n': schema \"your_schema\" already exists\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c6a0ecda9ed5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcreate\u001b[0m \u001b[0mschema\u001b[0m \u001b[0mYOUR_SCHEMA\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpsql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shajek/anaconda/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(sql, con, cur, params)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mpandas_sql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandasSQL_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_cursor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpandas_sql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shajek/anaconda/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1411\u001b[0m             ex = DatabaseError(\n\u001b[1;32m   1412\u001b[0m                 \"Execution failed on sql '%s': %s\" % (args[0], exc))\n\u001b[0;32m-> 1413\u001b[0;31m             \u001b[0mraise_with_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1415\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shajek/anaconda/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1399\u001b[0m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1402\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql '\n    create schema YOUR_SCHEMA;\n': schema \"your_schema\" already exists\n"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "    create schema YOUR_SCHEMA;\n",
    "\"\"\"\n",
    "psql.execute(sql, conn)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the Twenty News Groups dataset into a database table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "    -- Define external table to fetch data from HDFS\n",
    "    drop external table if exists YOUR_SCHEMA.twenty_news_groups_ext cascade;\n",
    "    create external table YOUR_SCHEMA.twenty_news_groups_ext\n",
    "    (\n",
    "        doc_id int,\n",
    "        contents text,\n",
    "        label text\n",
    "    ) location ('file://gpdb-sandbox.localdomain/home/gpadmin/data/20_newsgroups.tsv') \n",
    "    format 'CSV' (DELIMITER = E'\\t')\n",
    "    LOG ERRORS INTO YOUR_SCHEMA.twenty_news_groups_err\n",
    "    SEGMENT REJECT LIMIT 100;\n",
    "\n",
    "    -- create an internal table\n",
    "    drop table if exists YOUR_SCHEMA.twenty_news_groups cascade;\n",
    "    create table YOUR_SCHEMA.twenty_news_groups\n",
    "    as\n",
    "    (\n",
    "        select \n",
    "            *\n",
    "        from\n",
    "            YOUR_SCHEMA.twenty_news_groups_ext\n",
    "    ) distributed randomly;\n",
    "\"\"\"\n",
    "psql.execute(sql, conn)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>contents</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2156</td>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...</td>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4385</td>\n",
       "      <td>Newsgroups: comp.sys.mac.hardware\\nPath: canta...</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12219</td>\n",
       "      <td>Newsgroups: sci.electronics\\nPath: cantaloupe....</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3881</td>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu comp.sys.ibm.p...</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7870</td>\n",
       "      <td>Newsgroups: rec.autos\\nPath: cantaloupe.srv.cs...</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                           contents  \\\n",
       "0    2156  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...   \n",
       "1    4385  Newsgroups: comp.sys.mac.hardware\\nPath: canta...   \n",
       "2   12219  Newsgroups: sci.electronics\\nPath: cantaloupe....   \n",
       "3    3881  Xref: cantaloupe.srv.cs.cmu.edu comp.sys.ibm.p...   \n",
       "4    7870  Newsgroups: rec.autos\\nPath: cantaloupe.srv.cs...   \n",
       "\n",
       "                      label  \n",
       "0   comp.os.ms-windows.misc  \n",
       "1     comp.sys.mac.hardware  \n",
       "2           sci.electronics  \n",
       "3  comp.sys.ibm.pc.hardware  \n",
       "4                 rec.autos  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "    select \n",
    "        *\n",
    "    from\n",
    "       YOUR_SCHEMA.twenty_news_groups\n",
    "    order by random()\n",
    "    limit 10\n",
    "\"\"\"\n",
    "df = psql.read_sql(sql, conn)\n",
    "conn.commit()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tokenize the documents using a simple white-space tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>games</td>\n",
       "      <td>10128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>selling</td>\n",
       "      <td>6728</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>1163</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>3637</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>takes</td>\n",
       "      <td>933</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     token  doc_id  tf\n",
       "0    games   10128   1\n",
       "1  selling    6728   1\n",
       "2       of    1163   3\n",
       "3      the    3637  10\n",
       "4    takes     933   2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "    --1) Create inverted index, compute term frequencies\n",
    "    drop table if exists YOUR_SCHEMA.twenty_news_groups_term_frequencies cascade;\n",
    "    create table YOUR_SCHEMA.twenty_news_groups_term_frequencies\n",
    "    as\n",
    "    (\n",
    "        select\n",
    "            token,\n",
    "            doc_id,\n",
    "            count(*) as tf\n",
    "        from\n",
    "        (\n",
    "            select\n",
    "                doc_id,\n",
    "                regexp_split_to_table(\n",
    "                    -- replace non-alpha characters, except spaces\n",
    "                    regexp_replace(\n",
    "                        --convert to lower case\n",
    "                        --replace newlines/carriage returns to space\n",
    "                        regexp_replace(lower(contents), E'\\\\r|\\\\n', ' ', 'g'),\n",
    "                        E'[^a-zA-Z0-9_ ]', '', 'g'\n",
    "                    ),\n",
    "                    E'\\\\\\s+'\n",
    "                ) as token\n",
    "            from\n",
    "                YOUR_SCHEMA.twenty_news_groups\n",
    "        )q\n",
    "        group by token, doc_id    \n",
    "    ) distributed randomly;\n",
    "\"\"\"\n",
    "psql.execute(sql, conn)\n",
    "conn.commit()\n",
    "df = psql.read_sql(\"\"\"select * from YOUR_SCHEMA.twenty_news_groups_term_frequencies limit 10;\"\"\", conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Remove stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "    -- Remove stop words \n",
    "    drop table if exists YOUR_SCHEMA.twenty_news_groups_vocabulary cascade;\n",
    "    create table YOUR_SCHEMA.twenty_news_groups_vocabulary\n",
    "    as\n",
    "    (\n",
    "        select\n",
    "            token\n",
    "        from\n",
    "        (\n",
    "            select\n",
    "                token,\n",
    "                count(distinct doc_id) as num_docs\n",
    "            from\n",
    "                YOUR_SCHEMA.twenty_news_groups_term_frequencies\n",
    "            where\n",
    "                -- Remove stopwords\n",
    "                token not in (\n",
    "                    'a\\\\'s','able','about','above','according','accordingly','across','actually','after','afterwards','again','against','ain\\\\'t',\n",
    "                    'all','allow','allows','almost','alone','along','already','also','although','always','am','among','amongst','an','and',\n",
    "                    'another','any','anybody','anyhow','anyone','anything','anyway','anyways','anywhere','apart','appear','appreciate',\n",
    "                    'appropriate','are','aren\\\\'t','around','as','aside','ask','asking','associated','at','available','away','awfully',\n",
    "                    'be','became','because','become','becomes','becoming','been','before','beforehand','behind','being','believe','below',\n",
    "                    'beside','besides','best','better','between','beyond','both','brief','but','by','c\\\\'mon','c\\\\'s','came','can','can\\\\'t',\n",
    "                    'cannot','cant','cause','causes','certain','certainly','changes','clearly','co','com','come','comes','concerning','consequently',\n",
    "                    'consider','considering','contain','containing','contains','corresponding','could','couldn\\\\'t','course','currently','definitely',\n",
    "                    'described','despite','did','didn\\\\'t','different','do','does','doesn\\\\'t','doing','don\\\\'t','done','down','downwards','during',\n",
    "                    'each','edu','eg','eight','either','else','elsewhere','enough','entirely','especially','et','etc','even','ever','every',\n",
    "                    'everybody','everyone','everything','everywhere','ex','exactly','example','except','far','few','fifth','first','five',\n",
    "                    'followed','following','follows','for','former','formerly','forth','four','from','further','furthermore','get','gets',\n",
    "                    'getting','given','gives','go','goes','going','gone','got','gotten','greetings','had','hadn\\\\'t','happens','hardly','has',\n",
    "                    'hasn\\\\'t','have','haven\\\\'t','having','he','he\\\\'s','hello','help','hence','her','here','here\\\\'s','hereafter','hereby','herein',\n",
    "                    'hereupon','hers','herself','hi','him','himself','his','hither','hopefully','how','howbeit','however','i\\\\'d','i\\\\'ll','i\\\\'m',\n",
    "                    'i\\\\'ve','ie','if','ignored','immediate','in','inasmuch','inc','indeed','indicate','indicated','indicates','inner','insofar',\n",
    "                    'instead','into','inward','is','isn\\\\'t','it','it\\\\'d','it\\\\'ll','it\\\\'s','its','itself','just','keep','keeps','kept','know','knows',\n",
    "                    'known','last','lately','later','latter','latterly','least','less','lest','let','let\\\\'s','like','liked','likely','little','look',\n",
    "                    'looking','looks','ltd','mainly','many','may','maybe','me','mean','meanwhile','merely','might','more','moreover','most','mostly',\n",
    "                    'much','must','my','myself','name','namely','nd','near','nearly','necessary','need','needs','neither','never','nevertheless','new',\n",
    "                    'next','nine','no','nobody','non','none','noone','nor','normally','not','nothing','novel','now','nowhere','obviously','of','off',\n",
    "                    'often','oh','ok','okay','old','on','once','one','ones','only','onto','or','other','others','otherwise','ought','our','ours',\n",
    "                    'ourselves','out','outside','over','overall','own','particular','particularly','per','perhaps','placed','please','plus','possible',\n",
    "                    'presumably','probably','provides','que','quite','qv','rather','rd','re','really','reasonably','regarding','regardless','regards',\n",
    "                    'relatively','respectively','right','said','same','saw','say','saying','says','second','secondly','see','seeing','seem','seemed',\n",
    "                    'seeming','seems','seen','self','selves','sensible','sent','serious','seriously','seven','several','shall','she','should',\n",
    "                    'shouldn\\\\'t','since','six','so','some','somebody','somehow','someone','something','sometime','sometimes','somewhat','somewhere',\n",
    "                    'soon','sorry','specified','specify','specifying','still','sub','such','sup','sure','t\\\\'s','take','taken','tell','tends','th',\n",
    "                    'than','thank','thanks','thanx','that','that\\\\'s','thats','the','their','theirs','them','themselves','then','thence','there',\n",
    "                    'there\\\\'s','thereafter','thereby','therefore','therein','theres','thereupon','these','they','they\\\\'d','they\\\\'ll','they\\\\'re',\n",
    "                    'they\\\\'ve','think','third','this','thorough','thoroughly','those','though','three','through','throughout','thru','thus','to',\n",
    "                    'together','too','took','toward','towards','tried','tries','truly','try','trying','twice','two','un','under','unfortunately',\n",
    "                    'unless','unlikely','until','unto','up','upon','us','use','used','useful','uses','using','usually','value','various','very',\n",
    "                    'via','viz','vs','want','wants','was','wasn\\\\'t','way','we','we\\\\'d','we\\\\'ll','we\\\\'re','we\\\\'ve','welcome','well','went','were',\n",
    "                    'weren\\\\'t','what','what\\\\'s','whatever','when','whence','whenever','where','where\\\\'s','whereafter','whereas','whereby','wherein',\n",
    "                    'whereupon','wherever','whether','which','while','whither','who','who\\\\'s','whoever','whole','whom','whose','why','will',\n",
    "                    'willing','wish','with','within','without','won\\\\'t','wonder','would','would','wouldn\\\\'t','yes','yet','you','you\\\\'d','you\\\\'ll',\n",
    "                    'you\\\\'re','you\\\\'ve','your','yours','yourself','yourselves','zero'\n",
    "                )\n",
    "            group by token\n",
    "        )t1,\n",
    "        (\n",
    "            select\n",
    "                count(distinct doc_id) as corpus_size\n",
    "            from\n",
    "                YOUR_SCHEMA.twenty_news_groups_term_frequencies\n",
    "        ) t2\n",
    "        where \n",
    "            -- Only consider those tokens which have occurred in at least 2% of the documents\n",
    "            t1.num_docs >= 0.02*(t2.corpus_size)\n",
    "    ) distributed randomly;\n",
    "\"\"\"\n",
    "psql.execute(sql, conn)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocabulary_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vocabulary_size\n",
       "0              786"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  token\n",
       "0    10\n",
       "1    12\n",
       "2    16\n",
       "3  1992\n",
       "4    23\n",
       "5    27\n",
       "6     3\n",
       "7    32\n",
       "8     5\n",
       "9     7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Print the vocabulary size\n",
    "sql = \"\"\"\n",
    "    select\n",
    "        count(*) as vocabulary_size\n",
    "    from\n",
    "        YOUR_SCHEMA.twenty_news_groups_vocabulary\n",
    "\"\"\"\n",
    "df = psql.read_sql(sql, conn)\n",
    "vocabulary_size = df['vocabulary_size'][0]\n",
    "display(df)\n",
    "display(psql.read_sql(\"select * from YOUR_SCHEMA.twenty_news_groups_vocabulary limit 10\", conn))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stem the tokens using the PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In many NLP tasks including document classification and information retrieval, it is useful to work with the root form of words in documents than their derived or inflected forms. Truncating words into their root forms is called stemming. MADlib has an implementation of the classic [Porter Stemmer](http://madlib.incubator.apache.org/docs/latest/group__grp__stemmer.html). Let's try it out on a test sentence below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stem_token_arr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[My, mother, say, that, run, is, good, for, yo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      stem_token_arr\n",
       "0  [My, mother, say, that, run, is, good, for, yo..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "    select\n",
    "        madlib_1_10.stem_token_arr(tokens)\n",
    "    from\n",
    "    (\n",
    "        select\n",
    "            regexp_split_to_array(\n",
    "                'My mother says that running is good for your health',\n",
    "                E'\\\\\\s+'\n",
    "            ) as tokens\n",
    "    )q\n",
    "\"\"\"\n",
    "df = psql.read_sql(sql, conn)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
